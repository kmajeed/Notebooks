{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:96% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based classification methods\n",
    "\n",
    "In this notebook we will test out 3 different tree methods:\n",
    "\n",
    "* A single decision tree\n",
    "* A random forest\n",
    "* A gradient boosted tree classifier\n",
    "    \n",
    "We will be using a college dataset to try to classify colleges as Private or Public based off these features:\n",
    "\n",
    "    Private: A factor with levels No and Yes indicating private or public university\n",
    "    Apps: Number of applications received\n",
    "    Accept: Number of applications accepted\n",
    "    Enroll: Number of new students enrolled\n",
    "    Top10perc: Percentage new students from top 10% of H.S. class\n",
    "    Top25perc: Percentage new students from top 25% of H.S. class\n",
    "    F.Undergrad: Number of fulltime undergraduates\n",
    "    P.Undergrad: Number of parttime undergraduates\n",
    "    Outstate: Out-of-state tuition\n",
    "    Room.Board: Room and board costs\n",
    "    Books: Estimated book costs\n",
    "    Personal: Estimated personal spending\n",
    "    PhD: Percentage of faculty with Ph.D.â€™s\n",
    "    Terminal: Percentage of faculty with terminal degree\n",
    "    S.F.Ratio: Student/faculty ratio\n",
    "    perc.alumni: Percentage alumni who donate\n",
    "    Expend: Instructional expenditure per student\n",
    "    Grad.Rate: Graduation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('trees').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = spark.read.csv('data/College.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+------------------+------------------+----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+----------------+------------------+\n",
      "|summary|              School|Private|              Apps|            Accept|          Enroll|         Top10perc|         Top25perc|      F_Undergrad|      P_Undergrad|          Outstate|        Room_Board|             Books|          Personal|               PhD|          Terminal|         S_F_Ratio|       perc_alumni|          Expend|         Grad_Rate|\n",
      "+-------+--------------------+-------+------------------+------------------+----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+----------------+------------------+\n",
      "|  count|                 777|    777|               777|               777|             777|               777|               777|              777|              777|               777|               777|               777|               777|               777|               777|               777|               777|             777|               777|\n",
      "|   mean|                null|   null|3001.6383526383524|2018.8043758043757|779.972972972973| 27.55855855855856|  55.7966537966538|3699.907335907336|855.2985842985843| 10440.66924066924| 4357.526383526383| 549.3809523809524|1340.6422136422136| 72.66023166023166| 79.70270270270271|14.089703989703986|22.743886743886744|9660.17117117117| 65.46332046332046|\n",
      "| stddev|                null|   null|3870.2014844352884|  2451.11397099263| 929.17619013287|17.640364385452134|19.804777595131373|4850.420530887386|1522.431887295513|4023.0164841119727|1096.6964155935289|165.10536013709253|  677.071453590578|16.328154687939314|14.722358527903374|3.9583491352055478| 12.39180148937615|5221.76843985609|17.177709897155403|\n",
      "|    min|Abilene Christian...|     No|                81|                72|              35|                 1|                 9|              139|                1|              2340|              1780|                96|               250|                 8|                24|               2.5|                 0|            3186|                10|\n",
      "|    max|York College of P...|    Yes|             48094|             26330|            6392|                96|               100|            31643|            21836|             21700|              8124|              2340|              6800|               103|               100|              39.8|                64|           56233|               118|\n",
      "+-------+--------------------+-------+------------------+------------------+----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark MLlib needs data as two columnsc (\"label\",\"features\")\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Apps','Accept','Enroll','Top10perc','Top25perc','F_Undergrad','P_Undergrad', \n",
    "                                       'Outstate', 'Room_Board', 'Books', 'Personal', 'PhD', 'Terminal', 'S_F_Ratio', \n",
    "                                       'perc_alumni', 'Expend', 'Grad_Rate'],\n",
    "                            outputCol=\"features\")\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Private|count|\n",
      "+-------+-----+\n",
      "|     No|  212|\n",
      "|    Yes|  565|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.groupBy('Private').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Private column to a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"Private\", outputCol=\"PrivateIndex\")\n",
    "output_fixed = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output_fixed.select(\"features\",'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|PrivateIndex|\n",
      "+--------------------+------------+\n",
      "|[1660.0,1232.0,72...|         0.0|\n",
      "|[2186.0,1924.0,51...|         0.0|\n",
      "|[1428.0,1097.0,33...|         0.0|\n",
      "|[417.0,349.0,137....|         0.0|\n",
      "|[193.0,146.0,55.0...|         0.0|\n",
      "|[587.0,479.0,158....|         0.0|\n",
      "|[353.0,340.0,103....|         0.0|\n",
      "|[1899.0,1720.0,48...|         0.0|\n",
      "|[1038.0,839.0,227...|         0.0|\n",
      "|[582.0,498.0,172....|         0.0|\n",
      "|[1732.0,1425.0,47...|         0.0|\n",
      "|[2652.0,1900.0,48...|         0.0|\n",
      "|[1179.0,780.0,290...|         0.0|\n",
      "|[1267.0,1080.0,38...|         0.0|\n",
      "|[494.0,313.0,157....|         0.0|\n",
      "|[1420.0,1093.0,22...|         0.0|\n",
      "|[4302.0,992.0,418...|         0.0|\n",
      "|[1216.0,908.0,423...|         0.0|\n",
      "|[1130.0,704.0,322...|         0.0|\n",
      "|[3540.0,2001.0,10...|         1.0|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using default parameters\n",
    "dtc = DecisionTreeClassifier(labelCol='PrivateIndex',featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='PrivateIndex',featuresCol='features')\n",
    "gbt = GBTClassifier(labelCol='PrivateIndex',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models (its three models, so it might take some time)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------+-----------+----------+\n",
      "|            features|PrivateIndex|rawPrediction|probability|prediction|\n",
      "+--------------------+------------+-------------+-----------+----------+\n",
      "|[174.0,146.0,88.0...|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[247.0,189.0,100....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[261.0,192.0,111....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[281.0,266.0,139....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[285.0,280.0,208....|         1.0|    [0.0,4.0]|  [0.0,1.0]|       1.0|\n",
      "|[291.0,245.0,126....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[314.0,158.0,132....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[331.0,331.0,225....|         0.0|   [24.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[344.0,264.0,97.0...|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[353.0,340.0,103....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[355.0,300.0,142....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[360.0,329.0,108....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[368.0,317.0,159....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[372.0,362.0,181....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[385.0,340.0,193....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[434.0,321.0,141....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[460.0,340.0,167....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[461.0,381.0,174....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[462.0,402.0,146....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|[465.0,361.0,176....|         0.0|  [293.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "+--------------------+------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|            features|PrivateIndex|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|[174.0,146.0,88.0...|         0.0|[16.9220846522093...|[0.84610423261046...|       0.0|\n",
      "|[247.0,189.0,100....|         0.0|[19.8879874687252...|[0.99439937343626...|       0.0|\n",
      "|[261.0,192.0,111....|         0.0|[19.8879874687252...|[0.99439937343626...|       0.0|\n",
      "|[281.0,266.0,139....|         0.0|[19.7997161651201...|[0.98998580825600...|       0.0|\n",
      "|[285.0,280.0,208....|         1.0|[7.84080298786181...|[0.39204014939309...|       1.0|\n",
      "|[291.0,245.0,126....|         0.0|[18.4926853808226...|[0.92463426904113...|       0.0|\n",
      "|[314.0,158.0,132....|         0.0|[17.8672629508987...|[0.89336314754493...|       0.0|\n",
      "|[331.0,331.0,225....|         0.0|[16.2812049089912...|[0.81406024544956...|       0.0|\n",
      "|[344.0,264.0,97.0...|         0.0|[19.7144634955782...|[0.98572317477891...|       0.0|\n",
      "|[353.0,340.0,103....|         0.0|[19.7144634955782...|[0.98572317477891...|       0.0|\n",
      "|[355.0,300.0,142....|         0.0|[19.8517703538759...|[0.99258851769379...|       0.0|\n",
      "|[360.0,329.0,108....|         0.0|[18.2234250647184...|[0.91117125323592...|       0.0|\n",
      "|[368.0,317.0,159....|         0.0|[19.7108644074488...|[0.98554322037244...|       0.0|\n",
      "|[372.0,362.0,181....|         0.0|[19.4651836387853...|[0.97325918193926...|       0.0|\n",
      "|[385.0,340.0,193....|         0.0|[18.4949816940490...|[0.92474908470245...|       0.0|\n",
      "|[434.0,321.0,141....|         0.0|[19.8879874687252...|[0.99439937343626...|       0.0|\n",
      "|[460.0,340.0,167....|         0.0|[19.8205717383881...|[0.99102858691940...|       0.0|\n",
      "|[461.0,381.0,174....|         0.0|[19.8671318954572...|[0.99335659477286...|       0.0|\n",
      "|[462.0,402.0,146....|         0.0|[19.8671318954572...|[0.99335659477286...|       0.0|\n",
      "|[465.0,361.0,176....|         0.0|[19.8787973809030...|[0.99393986904515...|       0.0|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|            features|PrivateIndex|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|[174.0,146.0,88.0...|         0.0|[1.50072114099596...|[0.95263924179081...|       0.0|\n",
      "|[247.0,189.0,100....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[261.0,192.0,111....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[281.0,266.0,139....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[285.0,280.0,208....|         1.0|[-1.0290860050080...|[0.11322924586342...|       1.0|\n",
      "|[291.0,245.0,126....|         0.0|[1.54101320488511...|[0.95614523364235...|       0.0|\n",
      "|[314.0,158.0,132....|         0.0|[1.59036241135198...|[0.96010244018177...|       0.0|\n",
      "|[331.0,331.0,225....|         0.0|[1.09458376407703...|[0.89927252498822...|       0.0|\n",
      "|[344.0,264.0,97.0...|         0.0|[1.54203656541601...|[0.95623097570052...|       0.0|\n",
      "|[353.0,340.0,103....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[355.0,300.0,142....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[360.0,329.0,108....|         0.0|[1.77344757893413...|[0.97199302814844...|       0.0|\n",
      "|[368.0,317.0,159....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[372.0,362.0,181....|         0.0|[1.53919790472559...|[0.95599274466471...|       0.0|\n",
      "|[385.0,340.0,193....|         0.0|[1.54220511372796...|[0.95624508213595...|       0.0|\n",
      "|[434.0,321.0,141....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[460.0,340.0,167....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[461.0,381.0,174....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[462.0,402.0,146....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "|[465.0,361.0,176....|         0.0|[1.54158208101341...|[0.95619291657883...|       0.0|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"PrivateIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "gbt_acc = acc_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results!\n",
      "--------------------------------------------------------------------------------\n",
      "A single decision tree had an accuracy of: 93.33%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble had an accuracy of: 94.22%\n",
      "--------------------------------------------------------------------------------\n",
      "A ensemble using GBT had an accuracy of: 93.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*80)\n",
    "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*80)\n",
    "print('A ensemble using GBT had an accuracy of: {0:2.2f}%'.format(gbt_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc120_model = RandomForestClassifier(labelCol='PrivateIndex',featuresCol='features',numTrees=120).fit(train_data)\n",
    "rfc120_predictions = rfc120_model.transform(test_data)\n",
    "rfc120_acc = acc_evaluator.evaluate(rfc120_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc200_model = RandomForestClassifier(labelCol='PrivateIndex',featuresCol='features',numTrees=200).fit(train_data)\n",
    "rfc200_predictions = rfc200_model.transform(test_data)\n",
    "rfc200_acc = acc_evaluator.evaluate(rfc200_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc250_model = RandomForestClassifier(labelCol='PrivateIndex',featuresCol='features',numTrees=250).fit(train_data)\n",
    "rfc250_predictions = rfc250_model.transform(test_data)\n",
    "rfc250_acc = acc_evaluator.evaluate(rfc250_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results!\n",
      "--------------------------------------------------------------------------------\n",
      "A single decision tree had an accuracy of: 93.33%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble had an accuracy of: 94.22%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble of 120 trees had an accuracy of: 94.22%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble of 200 trees had an accuracy of: 94.22%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble of 250 trees had an accuracy of: 94.67%\n",
      "--------------------------------------------------------------------------------\n",
      "A ensemble using GBT had an accuracy of: 93.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*80)\n",
    "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble of 120 trees had an accuracy of: {0:2.2f}%'.format(rfc120_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble of 200 trees had an accuracy of: {0:2.2f}%'.format(rfc200_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble of 250 trees had an accuracy of: {0:2.2f}%'.format(rfc250_acc*100))\n",
    "print('-'*80)\n",
    "print('A ensemble using GBT had an accuracy of: {0:2.2f}%'.format(gbt_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Spark 2.2.1)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
